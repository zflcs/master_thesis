\chapter{引言}

\section{课题研究背景与意义}

近年来，云应用程序（例如网络搜索、社交网络、电子商务、实时媒体等）在日常生活中发挥着越来越重要的作用。为了保证良好的人机交互体验，这些应用程序需要在几十毫秒的时间尺度上对用户的操作作出响应，而它们通常将单个请求分散到数据中心的数百台计算机上运行的数千个通信服务，其中耗时最长的服务成为了影响端到端响应时间的主要因素，这要求每个参与的服务的尾部延迟在几百微秒的范围内；随着这些亿级用户应用的爆发式增长，数据中心面临的性能挑战已远超人机交互的低延迟需求，数据中心需要每秒钟能够处理数百万请求，现代计算机系统正经历着前所未有的吞吐量压力考验。

嵌入式实时系统应用也呈现出相似的发展趋势，其应用场景逐渐泛化，从传统的工业控制领域（工业化流控、车辆制造等）向消费级场景（智能家居、健康监护、车辆智能座舱等）逐渐渗透，催生出与新型技术融合的需求，模糊了工业与消费电子的传统界限。在消费端应用中，嵌入式实时系统开始集成轻量化人工智能模块，既要求系统保留实时响应能力的同时，还需要实现微型机器学习等新型功能；在车载智能座舱领域，嵌入式实时系统需要支持多媒体数据处理、车载网络通信、车辆控制等多种功能，既需要达到工业级安全标准的硬实时性要求，又需要满足娱乐性、互动性等消费级体验需求。

这些应用场景的复杂化对计算机系统的性能提出了复杂的要求，而操作系统作为计算机系统的核心软件组件，通过分层抽象机制实现了对底层硬件资源的统一管理，其进（线）程管理、内存管理、设备管理和文件系统等功能模块对物理层面的中央处理器（CPU）、存储器、输入输出设备以及网络接口等资源进行了标准化抽象，向上层应用提供了访问系统服务的接口。

任务调度作为操作系统的核心机制，其作用不仅体现在对 CPU 时间的直接分配上，还渗透至操作系统的其他功能模块中。例如，在进（线）程管理中，任务调度决定了进（线）程执行的顺序，针对不同的任务类型采取差异化的调度策略，既保证了交互式任务的响应速度，又维持了计算密集型任务的吞吐率；在设备管理模块中，中断机制作为连接应用程序与外部设备的核心桥梁，通过事件驱动的方式实现异步通信。当外部设备产生中断信号时，系统首先保存当前任务执行状态，随后调用中断服务程序解析设备事件，更新相关任务的状态，并将其重新加入调度队列，在中断返回路径上，触发任务调度机制进行决策，基于任务时效性要求评估是否需要立即进行任务切换，从而有效降低 I/O 任务的等待延迟，从而满足应用程序低延时的需求；

针对操作系统中的任务调度机制展开研究，是计算机系统研究的重要方向之一。本文基于软硬协作的方法，展开对中断响应与任务调度机制的研究，旨在降低系统的响应延时、提高系统的吞吐量，增强人机交互体验，以应对复杂多样化的应用场景需求。

\section{国内外研究现状}

\subsection{中断机制}

中断机制作为一种提高计算机工作效率的技术，最初是用于解决处理器忙等外部设备导致的效率低下问题，在硬件与软件之间构建起高效的协作桥梁。当外部设备完成 I/O 请求时，设备向 CPU 发送中断信号，CPU 被迫暂停当前执行的进（线）程，转而优先处理突发 I/O 事件。中断机制打破了传统顺序执行的局限性，使得计算机即能够快速响应键盘输入、网络数据传输等紧急任务，又能通过精密的时钟中断定期重新分配计算资源，从而营造出多进（线）程流畅运行的假象。

然而，中断机制为系统提供实时响应能力以及时分复用机制的同时，也引入了一些开销。每次中断触发时，CPU 必须暂停当前执行的指令流，保存通用寄存器、程序计数器等现场状态，当中断处理完成后恢复现场，造成直接开销；并且，中断处理程序可能覆盖原任务的指令/数据缓存内容，在原程序恢复执行时，需要重新加载，造成间接开销 \cite{Adam2014, gruss_kaslr_2017, Livio2010, David2007, Tsafrir2007}。

在早期，I/O 设备每秒只能完成几百个请求，传统的中断机制足以支持软件层面上的并发处理，由中断引起的开销在系统稳定性方面可以忽略不计。然而，现代高速 I/O 设备每秒可以完成数百万个请求 \cite{IntelOptane, WesternDigital, InterEthernet}。如果使用传统的中断机制，如此高的 I/O 请求完成频率可能会导致不可接受的上下文切换开销。目前，针对这个问题，已经展开了大量的研究工作，主要研究方向如下：

\begin{itemize}
    \item 轮询机制：为了避免中断频繁干扰处理器，一些研究和技术选择采用轮询机制 \cite{Caulfield2010, Yang2012, Dejan2014, lwn2024}。例如，IX \cite{AdamIX2014} 和 DPDK \cite{DPDK}（以及 SPDK \cite{SPDK}）直接将设备暴露给应用程序，并在用户空间实现轮询，绕过了内核和中断的需求。Intel 的 DDIO \cite{DDIO} 和 ARM 的 ACP \cite{nayak_comparison_2018} 允许网络设备直接将传入数据写入处理器缓存，通过将内存映射的 I/O 查询转换为缓存命中，显著提高了轮询效率。陈旭辉等人提出了一种根据外部事件发生频率分配优先级的方法，并基于这些优先级进行轮询，有效地提高了对外部事件的响应速度 \cite{Chen2010}。管海兵等人提出的 sEBP（智能基于事件的轮询模型）通过收集各种系统事件优化了网络卡的轮询机制\cite{Guan2013}。为了减少轮询中的高 CPU 开销，Linux 内核建议使用混合轮询 \cite{le2017latency, Stephen2017}。这种方法避免轮询整个 I/O 等待时间。相反，I/O 线程会被阻塞一段时间，然后无论 I/O 是否已完成都会被唤醒进行轮询。关键思想是，没有必要从 I/O 过程的开始就启动轮询，因为 I/O 操作需要一些时间来完成。但是，轮询机制 要求 CPU 必须定期主动查询设备状态，即使这些查询没有结果。这会导致更高的 CPU 利用率，尤其是在设备不太活跃的情况下 \cite{Chen2010,AlQahtani2007, Gao1996, Lee2022}。并且，轮询机制的响应时间受轮询间隔的限制，如果间隔很长，系统的响应可能会延迟，从而影响效率。
    
    \item 混合中断与轮询：除了单独使用中断或轮询机制外，一些研究 \cite{Langendoen1996, AlQahtani2007} 已尝试将两者结合起来，以保留它们各自的优势。Langendoen 等人结合了轮询、中断和线程管理，利用线程调度器感知任务等待外部事件的能力，当 CPU 空闲时，它采用轮询方式接收网络卡数据，并在有可运行线程时切换到中断方式 \cite{Langendoen1996}。AlQahtani 等人采用 EDP（使能-禁用中断和轮询）机制，根据系统负载灵活地在轮询和中断策略之间切换 \cite{AlQahtani2007}。然而，这些混合方法需要依赖启发式的策略，预设的启发式规则难以适应动态变化的负载。
    
    \item 硬件支持的快速上下文切换：大量的研究致力于优化中断上下文切换的开销\cite{Yamasaki2006, Suito2012, Wada2019, Lopez2022}。例如，RMTP（响应式多线程处理器）芯片已经在硬件中实现了资源分配、上下文切换和中断唤醒机制。其专用的上下文切换指令能够在四个时钟周期内完成一次上下文切换。此外，RMTP的硬件中断唤醒机制可以在单个时钟周期内切换到响应任务以处理中断\cite{Dodiu2012}。多管道寄存器架构（Multi Pipeline Register Architecture，MPRA）处理器也已经展示了在几个时钟周期内完成上下文切换的能力，并且利用这一特性优化了中断处理\cite{Gaitan2014,ZAGAN2017}。然而，这些基于特定硬件平台的优化方法缺乏通用性。
    
    \item 中断合并：尽管前述研究已经优化了单个中断上下文切换的开销，但并未解决由于中断数量过多导致的中断过载问题。因此，许多研究 \cite{salah_coalesce_2007, ahmad2009improving, Ahmad2011vICIC, Dong2011, GuanEICS2013, AmyTai2021} 开始探索中断合并技术。中断合并技术减少了CPU需要处理的中断数量，以避免中断过载。例如，Salah 等人评估了中断合并技术与传统中断处理的对比 \cite{salah_coalesce_2007}。Ahmad 等人提出了一个虚拟中断合并方案，用于在虚拟机监控器中实现虚拟SCSI硬件控制器 \cite{ahmad2009improving, Ahmad2011vICIC}。董耀祖等人进行了高效的中断合并和虚拟接收端扩展，充分利用了多核处理器的优势，用于网络I/O虚拟化 \cite{Dong2011, GuanEICS2013}。市场上许多网络卡和存储设备都内置了中断合并功能，但这些功能通常基于静态配置，缺乏动态调整能力。Amy Tai等人\cite{AmyTai2021}在静态配置的基础上引入了适应性中断合并，使设备能够根据请求的延迟敏感性自适应地合并中断。然而，中断合并与混合中断与轮询存在着相同的问题。
    
    \item 硬件智能：一些研究还在探索如何通过硬件增强来提升系统的智能水平。例如，G.R. Gao 等人提出的轮询 Watchdog 硬件扩展，只有在显式轮询无法及时处理到来的消息时才会触发中断，从而减少了不必要的中断 \cite{Gao1996}。在 Gomes 等人的研究工作中，中断控制器可以识别当前运行线程的优先级，并确保低优先级中断不会抢占高优先级线程的执行，有效地避免了由中断引起的优先级反转问题 \cite{Gomes2015}。Erwin 等人使用的队列内容寻址存储器（CAM）技术提供了一种高效组织和管理中断的新方法 \cite{Erwin1970}。Fabian Scheler 等人使用外围控制处理器（PCP）协处理器可以在中断发生时直接更新内存中的任务状态，只有当高优先级中断任务准备就绪时才通知CPU进行重新调度 \cite{SchelerHOPSL09}，然而，这种方法也有一定的局限性，因为 CPU 和 PCP 同时访问内存可能会导致高同步和互斥开销，有时会增加中断处理的延迟。这些方法的共同之处在于它们都利用了内核的任务调度器，通过增加与任务控制相关的属性（如任务优先级、状态和时间尺度）来增强它。然而，由于内核和硬件都访问内存中的任务控制块，因此需要额外的同步和互斥机制。
\end{itemize}

\subsection{任务调度}

任务调度机制直接决定了系统的性能表现，针对不同的应用场景需要的性能指标，目前已经存在着大量的研究工作。

源于中断机制的固有特性，低时延与高吞吐这两项指标是一对矛盾体。一方面，中断提供的抢占机制有效的缓解了传统轮询模式下的队头阻塞问题，保证关键 I/O 请求的优先处理，从而降低响应延时；另一方面，中断机制带来的上下文切换开销、缓存失效开销以及频繁中断造成的中断风暴等问题，会导致系统的吞吐量降低。很多研究工作围绕着这两项指标展开。Wierman 等人在论文 \cite{wierman2012tail} 中证明，没有单一的调度策略可以最小化所有可能工作负载的尾部延迟，在任务的尾部延迟较小时，FCFS（first come first served）策略的尾部延迟是渐进最优的；在任务的尾部延迟较大时，则 PS（processor sharing）策略的尾部延迟是渐进最优的。并且这些策略体现出明显的二分性，即在轻尾工作负载下表现良好的策略在重尾负载下表现较差，反之亦然。在此基础上，Prekas 等人在开展 ZygOS \cite{prekas2017zygos} 的研究工作时，对单队列和多队列进行了分析，证明了无论是 FCFS 还是 PS 调度策略，单队列的尾部延迟均优于多队列。近年来，有很多研究工作围绕着构建低时延服务进行。在上述的理论前提下，他们结合了操作系统的一些其他优化手段，成功构建了一些低时延服务 \cite{Adam2014, iyer2023achieving, kaffes2019shinjuku, ousterhout2019shenango, jia2024skyloft}。Shenango 保留额外的处理器核心用于满足高负载情况下的低延时要求\cite{ousterhout2019shenango}，但在低负载的情况下存在着 CPU 资源浪费的问题；Shinjuku \cite{kaffes2019shinjuku} 使用专门的调度线程为每个请求创建上下文来支持抢占和重调度，当工作线程上的某个请求耗时过多时，调度线程向该工作线程发起中断，让工作线程能够及时响应需要快速处理的请求；Concord \cite{iyer2023achieving} 则在 Shinjuku 的基础上进行了优化，它通过编译器插桩达到了用协作式调度近似 Shinjuku 中的抢占式调度的效果，减小了 Shinjuku 中工作线程由于中断抢占带来的开销，但它与 Shinjuku 都需要一个专用的调度核分发任务；Skyloft \cite{jia2024skyloft} 使用了 x86 架构下的用户态中断技术 \cite{x86_uintr}，提供了一个通用且高效的用户态调度框架，满足了应用程序多样化的需求，但它只能在特定的硬件平台上发挥优势。

随着吞吐量需求的增加，任务调度的对象也开始发生变化，开始由多线程模型向协程这种轻量级、且易于与异步机制结合的任务模型转化。近年来，以协程为任务单元的研究开始引起学术界和工业界的关注，DepFast \cite{Xuhao2022} 在分布式仲裁系统中使用协程；Capriccio \cite{vonBehren2003} 使用相互协作的用户态线程来实现可扩展的大规模 web server；Demikernel \cite{zhang2021demikernel} 利用了 Rust 无栈协程上下文切换低成本与适合基于状态机的异步事件处理机制的特点，能够在十几个时钟周期内完成任务切换，向应用程序提供异步 I/O；基于 Rust 协程实现的为嵌入式设备上运行的异步驱动生成框架 Embassy \cite{embassy} 在中断耗时和中断延迟方面远胜于用 C 语言实现的 FreeRTOS \cite{embassy_vs_freetos}。但这些基于协程模型的任务调度仍然需要中断机制来保证低延时的性能需求。

这些研究取得了相当不错的成果，但仍然存在一些问题。这些研究工作大多是基于软件层面的优化，甚至某些工作是针对特定的硬件设备展开，由软件来适配硬件资源（CPU 等）以及硬件特性（中断机制、I/O 设备特性），其中存在着硬件资源浪费等问题，而围绕着硬件展开的工作，限制了只能在特定硬件平台上才能发挥优势，缺乏通用性。

在应对复杂多样的应用场景时，中断机制与任务调度机制是相辅相成，单纯从某一机制展开研究无法满足复杂多样化的应用场景需求，关于任务调度中的调度策略、任务模型的研究已经足够全面，而中断机制的固有特性也不足以做出新的突破。因此，本文尝试从软硬件结合的角度出发，展开对中断响应与任务调度机制的研究，以期在降低系统的响应延时、提高系统的吞吐量方面取得新的突破。

\section{本文的主要研究内容与组织结构}

任务调度涉及到任务模型、调度算法、同步互斥、中断处理、通信等多个领域，其中每个领域都有众多的研究课题，针对任务调度机制展开研究，是一项复杂的系统性工程。

本文第一章为引言。在这一章中作者首先结合云应用和嵌入式实时应用的发展趋势，阐述了论文的研究背景以及现实意义，然后立足于中断响应和任务调度的性能，对国内外相关研究进行了详细的分析并介绍了各自的优缺点。

本文第二章为相关技术研究，作者从任务模型出发，介绍了任务模型的变迁过程，并介绍了在任务变迁过程中涉及到的任务调度算法、I/O 模型的变化，并介绍了用户态中断技术的研究现状。

本文第三章基于前文的研究内容，展开了基于软硬协同的中断响应和任务调度设计。相较于传统的基于性能指标进行的任务建模，作者基于任务运行环境进行建模，提出了一种基于执行流的任务模型。在此任务模型的基础上，作者提出了一种软硬协同的任务状态模型，在硬件中实现任务调度、中断处理以及任务通信等功能，定义了一套软硬件交互的接口。

本文第四章将第三章所述的设计方案与具体的硬件平台以及操作系统内核结合，落实到具体的硬件实现，以及与软件之间的适配，搭建了一个基于软硬协同的中断响应和任务调度的系统原型。

本文第五章对前两章所提出的设计方案与系统原型进行了验证试验，通过微基准测试以及综合性能测试，验证了设计方案的有效性。

论文第六章是总结与展望，作者在总结全文的基础上，指出了后续可能的研究方向。
